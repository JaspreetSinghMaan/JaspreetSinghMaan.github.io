<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <!-- Use the .htaccess and remove these lines to avoid edge case issues.
     More info: h5bp.com/i/378 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

  <!-- Our site title and description -->
  <title>Angel Xuan Chang | Angel Xuan Chang</title>

  <meta name="generator" content="DocPad v6.79.4" />

  <!-- Mobile viewport optimized: h5bp.com/viewport -->
  <meta name="viewport" content="width=device-width" />

  <!-- Shims: IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script async src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link  rel="stylesheet" href="/styles/twitter-bootstrap.css" /><link  rel="stylesheet" href="/styles/style.css" />
  <script  src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script  src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script><script  src="/scripts/bootstrap.min.js"></script><script  src="/scripts/script.js"></script>
</head>
<body>
  <div class="container">
    <section id="content" class="content">
      <nav class="navbar navbar-default">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="#"></a>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="index.html">Home</a></li>
        <li><a href="pubs.html">Publications</a></li>
        <li><a href="classes.html">Classes</a></li>
        <li><a href="group.html">Group</a></li>
        <li><a href="news.html">News</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<h1>Angel Xuan Chang</h1>

<div class="row">
  <div class="col-sm-8 pull-left" style="min-height: 280px; display: flex; flex-direction: column;">
    <p>
      I am an Assistant Professor at  <a href="https://www.sfu.ca/computing.html">Simon Fraser University</a>. 
       Prior to this, I was a visiting research scientist at <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research<a> and a research scientist at <a href="http://eloquent.ai">Eloquent Labs</a> working on dialogue.  I received my Ph.D. in <a href="http://cs.stanford.edu/">Computer Science</a> from <a href="http://www.stanford.edu/">Stanford</a>, where I was part of the <a href="http://nlp.stanford.edu/">Natural Language Processing Group</a> and advised by <a href="http://nlp.stanford.edu/~manning/">Chris Manning</a>.
       My research focuses on connecting language to 3D representations of shapes and scenes and grounding of language for embodied agents in indoor environments.  I have worked on methods for synthesizing 3D <a href="http://nlp.stanford.edu/projects/text2scene.shtml">scenes</a> and <a href="http://text2shape.stanford.edu/">shapes</a> from natural language, and various datasets for 3D scene understanding. In general, I am interested in the semantics of shapes and scenes, the representation and acquisition of common sense knowledge, and reasoning using probabilistic models.
      Some of my other <a href="http://www.coiraweb.com/poignance/angel">interests</a> include <a href="http://www.coiraweb.com/poignance/angel/art/reflections.html">drawing</a> and <a href="http://www.coiraweb.com/poignance/angel/dance/dance.html">dance</a>.
    </p>
    <p>
      
      <h3>News</h3>
      <ul>
        
        
          <li>May 2021 - Challenges and Workshops at CVPR 2021.  <ul><li>June 19th - <a href='https://sites.google.com/view/cvpr2021-3d-vision-robotics'>3D Vision and Robotics</a></li><li>June 20th - <a href='http://www.scan-net.org/cvpr2021workshop/'>ScanNet Indoor Scene Understanding Challenge</a></li><li>June 20th - <a href='http://multion-challenge.cs.sfu.ca/'>Multi-Object Navigation Challenge</a> at the <a href='https://embodied-ai.org/'>Embodied-AI workshop</a></li><li>June 25th - <a href='https://learn3dg.github.io/'>Learning to Generate 3D Shapes and Scenes</a></li><li>June 25th - <a href='https://language3dscenes.github.io//'>Language for 3D Scenes</a></li></ul></li>
        
          <li>March 2021 - Three paper accepted at CVPR 2021.  Great job by Madhawa, Qirui, Jiaqi, Lewis, Dave, and Ali!</li>
        
          <li>January 2021 - I'm co-chairing <a href='https://sgp2021.github.io/'>SGP (Symposium for Geometry Processing)</a> with <a href='https://www.cs.toronto.edu/~jacobson/'>Alec Jacobson</a>.</li>
        
          <li>November 25, 2020 - Invited talk at <a href='https://caida.ubc.ca/event/emerging-technologies-bcs-ai-showcase'>Emerging Technologies: BC's AI Showcase</a></li>
        
          <li>November, 2020 - Whitepaper on <a href='https://arxiv.org/pdf/2011.01975.pdf'>Rearrangement: A Challenge for Embodied AI</a></li>
        
      </ul>
      <a href="news.html">More...</a>
      
    </p>
  </div>
  <div class="col-sm-4 text-right pull-right">
    <img src="files/angel.jpg" alt="Angel Xuan Chang" width="150px"/>
    <div style="font-family:monospace;">
      angelx-{at}-sfu-[dot]-ca
    </div><br>
    Assistant Professor<br/>
    School of Computing Science<br/>
    <a href="https://www.sfu.ca/computing.html">Simon Fraser University</a><br/>
    <a href="https://gruvi.cs.sfu.ca/">GrUVi Lab</a> | <a href="http://natlang.cs.sfu.ca/">SFU NatLang</a> | <a href="http://ml.cs.sfu.ca/#/">SFU AI/ML</a><br/> 
    Canada CIFAR AI Chair (<a href="https://www.amii.ca/">Amii</a>)<br/>
    TUM-IAS Hans Fischer Fellow<br/>
    <a href="https://scholar.google.com/citations?user=8gfs8XIAAAAJ&hl=en">Google Scholar</a>
  </div>
</div>
<br>



<div class="row">
  <div class="col-sm-12">

    
    <div class="panel panel-default">
      <div class="panel-heading">
        <h2>Publications</h2>
        <button class="badge badge-primary selectable pub_badge" id="pub_all" onclick="util.showAllPubs()">all</button>
        
          <button class="badge badge-primary selectable pub_badge" id="pub_nlp" onclick="util.showPubs('maintags', 'nlp')">nlp</button>
        
          <button class="badge badge-primary selectable pub_badge" id="pub_vision" onclick="util.showPubs('maintags', 'vision')">vision</button>
        
          <button class="badge badge-primary selectable pub_badge" id="pub_graphics" onclick="util.showPubs('maintags', 'graphics')">graphics</button>
        
          <button class="badge badge-primary selectable pub_badge" id="pub_hci" onclick="util.showPubs('maintags', 'hci')">hci</button>
        
      </div>
      <div class="panel-body">
      
            
      
      
        <div class="year">
          <h3>2021</h3>
                  
          <div class="row paper vertical-center" id="pub_0" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://daveredrum.github.io/Scan2Cap/"><img src="files/scan2cap.jpg" alt="Scan2Cap: Context-aware Dense Captioning in RGB-D Scans" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://daveredrum.github.io/Scan2Cap/">
                Scan2Cap: Context-aware Dense Captioning in RGB-D Scans
                </a>
              </h4>
              
                
                <a href="http://www.niessnerlab.org/members/zhenyu_chen/profile.html">Dave Zhenyu Chen</a>, 
              
                
                <a href="https://aligholami.github.io/">Ali Gholami</a>, 
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              CVPR 2021<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/2012.02206.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/daveredrum/Scan2Cap">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://daveredrum.github.io/Scan2Cap/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_1" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://3dlg-hcvc.github.io/plan2scene/"><img src="files/plan2scene.png" alt="Plan2Scene: Converting Floorplans to 3D Scenes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://3dlg-hcvc.github.io/plan2scene/">
                Plan2Scene: Converting Floorplans to 3D Scenes
                </a>
              </h4>
              
                
                <a href="https://madhawav.github.io/">Madhawa Vidanapathirana</a>, 
              
                
                Qirui Wu, 
              
                
                <a href="https://www.cs.sfu.ca/~furukawa/">Yasutaka Furukawa</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a><br>
              
              CVPR 2021<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/2106.05375.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/3dlg-hcvc/plan2scene">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://3dlg-hcvc.github.io/plan2scene/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_2" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://3dlg-hcvc.github.io/mirror3d/"><img src="files/mirror3d.png" alt="Mirror3D: Depth Refinement for Mirror Surfaces" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://3dlg-hcvc.github.io/mirror3d/">
                Mirror3D: Depth Refinement for Mirror Surfaces
                </a>
              </h4>
              
                
                <a href="https://christinatan0704.github.io/mysite/">Jiaqi Tan</a>, 
              
                
                <a href="https://lewislinn.github.io/">Weijie (Lewis) Lin</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a><br>
              
              CVPR 2021<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/2106.06629.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/3dlg-hcvc/mirror3d">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://3dlg-hcvc.github.io/mirror3d/">webpage</a> 
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2020</h3>
                  
          <div class="row paper vertical-center" id="pub_3" data-maintags="">
            <div class="col-sm-3 paper-img">
            
              <a href="https://arxiv.org/pdf/2011.01975.pdf"><img src="files/rearrangement.png" alt="Rearrangement: A Challenge for Embodied AI" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Rearrangement: A Challenge for Embodied AI
                
              </h4>
              
                
                <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>, 
              
                
                <a href="https://www.doc.ic.ac.uk/~ajd/">Andrew J. Davison</a>, 
              
                
                <a href="https://www.cs.princeton.edu/~jiadeng/">Jia Deng</a>, 
              
                
                <a href="http://vladlen.info/">Vladlen Koltun</a>, 
              
                
                <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>, 
              
                
                <a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a>, 
              
                
                Igor Mordatch, 
              
                
                <a href="https://cs.stanford.edu/~roozbeh/">Roozbeh Mottaghi</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a><br>
              
              arXiv preprint arXiv:2011.01975 [cs.AI], November 2020<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/2011.01975.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_4" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://visual.cs.brown.edu/projects/articulations-webpage/"><img src="files/maps.png" alt="Motion Annotation Programs: A Scalable Approach to Annotating Kinematic. Articulations in Large 3D Shape Collections" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://visual.cs.brown.edu/projects/articulations-webpage/">
                Motion Annotation Programs: A Scalable Approach to Annotating Kinematic. Articulations in Large 3D Shape Collections
                </a>
              </h4>
              
                
                Xianghao Xu, 
              
                
                David Charatan, 
              
                
                Sonia Raychaudhuri, 
              
                
                <a href="https://jianghanxiao.github.io/">Hanxiao (Shawn) Jiang</a>, 
              
                
                Mae Heitmann, 
              
                
                <a href="http://www.vovakim.com/">Vladmir Kim</a>, 
              
                
                <a href="https://www.cse.iitb.ac.in/~sidch/">Siddhartha Chaudhuri</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://dritchie.github.io/">Daniel Ritchie</a><br>
              
              3DV 2020<br>
              
              
                 
                   
                   <a href="http://visual.cs.brown.edu/projects/articulations-webpage/articulations_3dv2020.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/brownvc/articulations">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://articulations.cs.brown.edu/">demo</a> 
                   
                 
              
                 
              
               | <a href="http://visual.cs.brown.edu/projects/articulations-webpage/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_5" data-maintags="ml,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://shivanshpatel35.github.io/multi-ON/"><img src="files/multion.jpg" alt="Multi-ON: Benchmarking Semantic Map Memory using Multi-Object Navigation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://shivanshpatel35.github.io/multi-ON/">
                Multi-ON: Benchmarking Semantic Map Memory using Multi-Object Navigation
                </a>
              </h4>
              
                
                <a href="https://saimwani.github.io/">Saim Wani</a>, 
              
                
                <a href="https://shivanshpatel35.github.io/">Shivansh Patel</a>, 
              
                
                <a href="https://unnat.github.io/">Unnat Jain</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a><br>
              
              NeurIPS 2020<br>
              
              
                 
                   
                   <a href="https://shivanshpatel35.github.io/multi-ON/resources/MultiON.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/saimwani/multiON">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://shivanshpatel35.github.io/multi-ON/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_6" data-maintags="hci,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://research.tableau.com/paper/sneak-pique-exploring-autocompletion-data-discovery-scaffold-supporting-visual-analysis"><img src="https://research.tableau.com/sites/default/files/uploads/sneakpique_1.png" alt="Sneak Pique: Exploring Autocompletion as a Data Discovery Scaffold for Supporting Visual Analysis" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://research.tableau.com/paper/sneak-pique-exploring-autocompletion-data-discovery-scaffold-supporting-visual-analysis">
                Sneak Pique: Exploring Autocompletion as a Data Discovery Scaffold for Supporting Visual Analysis
                </a>
              </h4>
              
                
                <a href="https://research.tableau.com/user/vidya-setlur">Vidya Setlur</a>, 
              
                
                <a href="https://www.yorku.ca/enamulh/">Enamul Hoque</a>, 
              
                
                <a href="https://dhkim16.github.io/">Dae Hyun Kim</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              UIST 2020<br>
              
              
                 
                   
                   <a href="https://research.tableau.com/sites/default/files/Autocomplete-UIST2020.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://research.tableau.com/paper/sneak-pique-exploring-autocompletion-data-discovery-scaffold-supporting-visual-analysis">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_7" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://daveredrum.github.io/ScanRefer/"><img src="files/scanrefer.jpg" alt="ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://daveredrum.github.io/ScanRefer/">
                ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language
                </a>
              </h4>
              
                
                <a href="http://www.niessnerlab.org/members/zhenyu_chen/profile.html">Dave Zhenyu Chen</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a><br>
              
              ECCV 2020<br>
              
              
                 
                   
                   <a href="https://daveredrum.github.io/ScanRefer/davezchen_eccv2020_scanrefer.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/daveredrum/ScanRefer">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/">benchmark</a> 
                   
                 
              
                 
              
                 
              
               | <a href="https://daveredrum.github.io/ScanRefer/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_8" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://sapien.ucsd.edu/"><img src="files/sapien.png" alt="SAPIEN: a SimulAted Part-based Interactive ENvironment" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://sapien.ucsd.edu/">
                SAPIEN: a SimulAted Part-based Interactive ENvironment
                </a>
              </h4>
              
                
                <a href="https://www.fbxiang.com/">Fanbo Xiang</a>, 
              
                
                <a href="https://yzqin.github.io/">Yuzhe Qin</a>, 
              
                
                <a href="https://cs.stanford.edu/~kaichun">Kaichun Mo</a>, 
              
                
                Yikuan Xia, 
              
                
                <a href="https://berniezhu.github.io/">Hao Zhu</a>, 
              
                
                <a href="https://fangchenliu.github.io/">Fangchen Liu</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~mil070/">Minghua Liu</a>, 
              
                
                <a href="https://jianghanxiao.github.io/">Hanxiao (Shawn) Jiang</a>, 
              
                
                Yifu Yuan, 
              
                
                <a href="http://ai.stanford.edu/~hewang/">He Wang</a>, 
              
                
                <a href="https://cs.stanford.edu/~ericyi/">Li Yi</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a><br>
              
              CVPR 2020<br>
              
              
                 
                   
                   <a href="https://arxiv.org/abs/2003.08515">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://sapien.ucsd.edu/">webpage</a> 
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2019</h3>
                  
          <div class="row paper vertical-center" id="pub_9" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://www.aclweb.org/anthology/K19-1037.pdf"><img src="files/mimic.png" alt="Mimic and Rephrase: Reflective Listening in Open-Ended Dialogue" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Mimic and Rephrase: Reflective Listening in Open-Ended Dialogue
                
              </h4>
              
                
                Justin Dieter, 
              
                
                Tian Wang, 
              
                
                <a href="http://cs.stanford.edu/~angeli/">Gabor Angeli</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://arun.chagantys.org/">Arun Tejasvi Chaganty</a><br>
              
              CONLL 2019<br>
              
              
                 
                   
                   <a href="https://www.aclweb.org/anthology/K19-1037.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/square/MimicAndRephrase">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_10" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://drive.google.com/file/d/1CJCM6EQyeUWwxdk6tl8cVxEIhV7s3DoA/view"><img src="https://dritchie.github.io/img/pubthumbs/graphsynth.png" alt="PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks
                
              </h4>
              
                
                <a href="https://kwang-ether.github.io/">Kai Wang</a>, 
              
                
                Yu-An Lin, 
              
                
                Ben Weissmann, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://dritchie.github.io/">Daniel Ritchie</a><br>
              
              SIGGRAPH 2019<br>
              
              
                 
                   
                   <a href="https://drive.google.com/file/d/1CJCM6EQyeUWwxdk6tl8cVxEIhV7s3DoA/view">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/brownvc/planit">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_11" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://www.yifeishi.net/hierarchylayout.html"><img src="files/hierarchylayout.jpg" alt="Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://www.yifeishi.net/hierarchylayout.html">
                Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction
                </a>
              </h4>
              
                
                <a href="http://www.yifeishi.net/">Yifei Shi</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                Zhelun Wu, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="https://kevinkaixu.net/">Kai Xu</a><br>
              
              CVPR 2019, arXiv:1903.03757 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/1903.03757">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/yifeishi/HierarchyLayout">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://www.yifeishi.net/hierarchylayout.html">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_12" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://cs.stanford.edu/~kaichun/partnet/"><img src="https://cs.stanford.edu/~kaichun/partnet/images/teaser.png" alt="PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://cs.stanford.edu/~kaichun/partnet/">
                PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding
                </a>
              </h4>
              
                
                <a href="https://cs.stanford.edu/~kaichun">Kaichun Mo</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~shz338/">Shilin Zhu</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://cs.stanford.edu/~ericyi/">Li Yi</a>, 
              
                
                <a href="http://acsweb.ucsd.edu/~stripath/">Subarna Tripathi</a>, 
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a><br>
              
              CVPR 2019, arXiv:1812.02713 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/abs/1812.02713">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="https://youtu.be/7pEuoxmb-MI">video</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://cs.stanford.edu/~kaichun/partnet/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_13" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://arxiv.org/pdf/1811.11187.pdf"><img src="files/scan2cad.png" alt="Scan2CAD: Learning CAD Model Alignment in RGB-D Scans" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Scan2CAD: Learning CAD Model Alignment in RGB-D Scans
                
              </h4>
              
                
                <a href="https://niessnerlab.org/members/armen_avetisyan/profile.html">Armen Avetisyan</a>, 
              
                
                <a href="https://niessnerlab.org/members/manuel_dahnert/profile.html">Manuel Dahnert</a>, 
              
                
                <a href="http://cs.stanford.edu/people/adai">Angela Dai</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a><br>
              
              CVPR 2019 (oral), arXiv:1811.11187 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/1811.11187.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/skanti/Scan2CAD">code</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://www.youtube.com/watch?v=PiHSYpgLTfA">video</a> 
                   
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://kaldir.vc.in.tum.de/scan2cad_benchmark/">benchmark</a> 
                   
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2018</h3>
                  
          <div class="row paper vertical-center" id="pub_14" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://dritchie.github.io/pdf/deepsynth.pdf"><img src="http://msavva.github.io/files/deepsynth.png" alt="Deep Convolutional Priors for Indoor Scene Synthesis" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Deep Convolutional Priors for Indoor Scene Synthesis
                
              </h4>
              
                
                <a href="https://kwang-ether.github.io/">Kai Wang</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://dritchie.github.io/">Daniel Ritchie</a><br>
              
              SIGGRAPH 2018<br>
              
              
                 
                   
                   <a href="https://dritchie.github.io/pdf/deepsynth.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/brownvc/deep-synth">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_15" data-maintags="ai,preprint">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                On evaluation of embodied navigation agents
                
              </h4>
              
                
                <a href="https://www.panderson.me/">Peter Anderson</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.cmu.edu/~dchaplot/">Devendra Singh Chaplot</a>, 
              
                
                <a href="https://dosovits.github.io/">Alexey Dosovitskiy</a>, 
              
                
                <a href="http://saurabhg.web.illinois.edu/">Saurabh Gupta</a>, 
              
                
                <a href="http://vladlen.info/">Vladlen Koltun</a>, 
              
                
                <a href="https://cs.gmu.edu/~kosecka/">Jana Kosecka</a>, 
              
                
                <a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a>, 
              
                
                <a href="https://cs.stanford.edu/~roozbeh/">Roozbeh Mottaghi</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="https://cs.stanford.edu/~amirz/">Amir R. Zamir</a><br>
              
              arXiv preprint arXiv:1807.06757 [cs.AI], July 2018<br>
              
              
                 
                   
                   <a href="https://arxiv.org/abs/1807.06757">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_16" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://text2shape.stanford.edu/"><img src="http://msavva.github.io/files/text2shape.png" alt="Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://text2shape.stanford.edu/">
                Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings
                </a>
              </h4>
              
                
                Kevin Chen, 
              
                
                <a href="https://chrischoy.github.io/">Christopher B. Choy</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a><br>
              
              Proceedings of ACCV 2018 (oral), arXiv:1803.08495 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/abs/1803.08495">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/kchen92/text2shape/">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://text2shape.stanford.edu/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_18" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://im2pano3d.cs.princeton.edu/"><img src="http://im2pano3d.cs.princeton.edu/teaser.jpg" alt="Im2Pano3D: Extrapolating 360 Structure and Semantics Beyond the Field of View" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://im2pano3d.cs.princeton.edu/">
                Im2Pano3D: Extrapolating 360 Structure and Semantics Beyond the Field of View
                </a>
              </h4>
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://andyzeng.github.io/">Andy Zeng</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a><br>
              
              Proceedings of CVPR 2018, arXiv:1712.04569 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/abs/1712.04569">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://im2pano3d.cs.princeton.edu/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_19" data-maintags="nlp,resources">
            <div class="col-sm-3 paper-img">
            
              <a href="http://compling.hss.ntu.edu.sg/events/2018-gwc/pdfs/GWC2018_paper_66.pdf"><img src="files/wordnetLink.png" alt="Linking WordNet to 3D Shapes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Linking WordNet to 3D Shapes
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                Rishi Mago, 
              
                
                Pranav Krishna, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="https://www.cs.princeton.edu/~fellbaum/">Christiane Fellbaum</a><br>
              
              Proceedings of Global WordNet Conference 2018<br>
              
              
                 
                   
                   <a href="http://compling.hss.ntu.edu.sg/events/2018-gwc/pdfs/GWC2018_paper_66.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2017</h3>
                  
          <div class="row paper vertical-center" id="pub_17" data-maintags="ai,preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="https://www.minosworld.org/"><img src="https://github.com/minosworld/minos/raw/master/docs/img/video_thumbnail.png" alt="MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://www.minosworld.org/">
                MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments
                </a>
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://dosovits.github.io/">Alexey Dosovitskiy</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://vladlen.info/">Vladlen Koltun</a><br>
              
              arXiv:1712.03931 [cs.LG]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/abs/1712.03931">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/minosworld/minos">code</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://youtu.be/c0mL9K64q84">video</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://www.minosworld.org/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_20" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://cseweb.ucsd.edu/~haosu/papers/3dv2017_attribute_transfer.pdf"><img src="http://msavva.github.io/files/attributeTransfer.png" alt="Cross-modal Attribute Transfer for Rescaling 3D Models" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Cross-modal Attribute Transfer for Rescaling 3D Models
                
              </h4>
              
                
                <a href="https://linsats.github.io/">Lin Shao</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a><br>
              
              Proceedings of 3DV 2017<br>
              
              
                 
                   
                   <a href="http://cseweb.ucsd.edu/~haosu/papers/3dv2017_attribute_transfer.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_21" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://niessner.github.io/Matterport/"><img src="http://msavva.github.io/files/matterport3d.png" alt="Matterport3D: Learning from RGB-D Data in Indoor Environments" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://niessner.github.io/Matterport/">
                Matterport3D: Learning from RGB-D Data in Indoor Environments
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://cs.stanford.edu/people/adai">Angela Dai</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="https://mhalber.github.io/">Maciej Halber</a>, 
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://andyzeng.github.io/">Andy Zeng</a>, 
              
                
                <a href="http://robots.princeton.edu/people/yindaz/">Yinda Zhang</a><br>
              
              Proceedings of 3DV 2017, arXiv:1709.06158 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/1709.06158.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/niessner/Matterport">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://niessner.github.io/Matterport/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_22" data-maintags="vision,preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="https://arxiv.org/pdf/1704.02393.pdf"><img src="http://msavva.github.io/files/viewsets.png" alt="Learning Where to Look: Data-Driven Viewpoint Set Selection for 3D Scenes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Learning Where to Look: Data-Driven Viewpoint Set Selection for 3D Scenes
                
              </h4>
              
                
                <a href="http://www.kylegenova.com/">Kyle Genova</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a><br>
              
              arXiv:1704.02393 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/1704.02393.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_23" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://www.scan-net.org/"><img src="files/scannet.jpg" alt="ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://www.scan-net.org/">
                ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes
                </a>
              </h4>
              
                
                <a href="http://cs.stanford.edu/people/adai">Angela Dai</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="https://mhalber.github.io/">Maciej Halber</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a><br>
              
              Proceedings of CVPR 2017 (spotlight), arXiv:1702.04405 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/1702.04405.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="https://github.com/ScanNet/ScanNet">code</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://www.youtube.com/watch?v=Olx4OnoZWQQ">video</a> 
                   
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://kaldir.vc.in.tum.de/scannet_benchmark/">benchmark</a> 
                   
                 
              
                 
              
                 
              
               | <a href="http://www.scan-net.org/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_24" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://vision.princeton.edu/projects/2016/SSCNet/"><img src="http://vision.princeton.edu/projects/2016/SSCNet/thumbnail.jpg" alt="Semantic Scene Completion from a Single Depth Image" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://vision.princeton.edu/projects/2016/SSCNet/">
                Semantic Scene Completion from a Single Depth Image
                </a>
              </h4>
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://yf.io/">Fisher Yu</a>, 
              
                
                <a href="http://andyzeng.github.io/">Andy Zeng</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a><br>
              
              Proceedings of CVPR 2017 (oral), arXiv:1611.08974 [cs.CV]<br>
              
              
                 
                   
                   <a href="https://arxiv.org/pdf/1611.08974v1.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://vision.princeton.edu/projects/2016/SSCNet/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_25" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://www.aclweb.org/anthology/E17-1044.pdf"><img src="files/quote-attribution.png" alt="A Two-stage Sieve Approach to Quote Attribution" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                A Two-stage Sieve Approach to Quote Attribution
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/~muzny/">Grace Muzny</a>, 
              
                
                Michael Fang, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              Proceedings of EACL 2017<br>
              
              
                 
                   
                   <a href="https://www.aclweb.org/anthology/E17-1044.pdf">pdf</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/~muzny/quoteli.html">code</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/~muzny/quoteli.html">data</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_26" data-maintags="preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="http://arxiv.org/abs/1703.00061.pdf"><img src="http://msavva.github.io/files/scenesuggest.png" alt="SceneSuggest: Context-driven 3D Scene Design" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                SceneSuggest: Context-driven 3D Scene Design
                
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~maneesh/">Maneesh Agrawala</a><br>
              
              arXiv:1703.00061 [cs.CG], March 2017<br>
              
              
                 
                   
                   <a href="http://arxiv.org/abs/1703.00061.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://aspis.cmpt.sfu.ca/scene-toolkit/scene-suggest.html">demo</a> 
                   
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_27" data-maintags="preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="http://arxiv.org/abs/1703.00050.pdf"><img src="http://msavva.github.io/files/sceneseer.png" alt="SceneSeer: 3D Scene Design with Natural Language" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                SceneSeer: 3D Scene Design with Natural Language
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://www.mihaileric.com/">Mihail Eric</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              arXiv:1703.00050 [cs.CG], March 2017<br>
              
              
                 
                   
                   <a href="http://arxiv.org/abs/1703.00050.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://aspis.cmpt.sfu.ca/scene-toolkit/text2scene.html">demo</a> 
                   
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2016</h3>
                  
          <div class="row paper vertical-center" id="pub_28" data-maintags="hci,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://research.tableau.com/paper/eviza-natural-language-interface-visual-analysis"><img src="https://research.tableau.com/sites/default/files/uploads/eviza_teaser.png" alt="Eviza: A Natural Language Interface for Visual Analysis" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://research.tableau.com/paper/eviza-natural-language-interface-visual-analysis">
                Eviza: A Natural Language Interface for Visual Analysis
                </a>
              </h4>
              
                
                <a href="https://research.tableau.com/user/vidya-setlur">Vidya Setlur</a>, 
              
                
                <a href="https://research.tableau.com/user/sarah-battersby">Sarah E. Battersby</a>, 
              
                
                <a href="https://research.tableau.com/user/melanie-tory">Melanie Tory</a>, 
              
                
                <a href="https://research.tableau.com/user/rich-gossweiler">Rich Gossweiler</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              UIST 2016<br>
              
              
                 
                   
                   <a href="https://research.tableau.com/sites/default/files/uist4832-setlurA_0.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="https://research.tableau.com/paper/eviza-natural-language-interface-visual-analysis">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_29" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/pigraphs/"><img src="http://graphics.stanford.edu/projects/pigraphs/pigraphs.png" alt="PiGraphs: Learning Interaction Snapshots from Observations" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/pigraphs/">
                PiGraphs: Learning Interaction Snapshots from Observations
                </a>
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, 
              
                
                <a href="https://techmatt.github.io/">Matthew Fisher</a>, 
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a><br>
              
              SIGGRAPH 2016<br>
              
              
                 
                   
                   <a href="http://graphics.stanford.edu/projects/pigraphs/">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://graphics.stanford.edu/projects/pigraphs/">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://graphics.stanford.edu/projects/pigraphs/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_30" data-maintags="nlp,preprint">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Evaluating the word-expert approach for Named-Entity Disambiguation
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a><br>
              
              arXiv:1603.04767 [cs.CL], March 2016<br>
              
              
                 
                   
                   <a href="http://arxiv.org/pdf/1603.04767v1">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2015</h3>
                  
          <div class="row paper vertical-center" id="pub_31" data-maintags="thesis">
            <div class="col-sm-3 paper-img">
            
              <a href="https://purl.stanford.edu/vg064sy5087"><img src="files/text2scene.png" alt="Text to 3D scene generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Text to 3D scene generation
                
              </h4>
              
                <b>
                Angel X. Chang<br></b>
              
              Ph.D. dissertation, Department of Computer Science, Stanford University, 2015<br>
              
              
                 
                   
                   <a href="https://purl.stanford.edu/vg064sy5087">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_32" data-maintags="preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="http://shapenet.cs.stanford.edu/"><img src="files/shapenet.png" alt="ShapeNet: An Information-Rich 3D Model Repository" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://shapenet.cs.stanford.edu/">
                ShapeNet: An Information-Rich 3D Model Repository
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, 
              
                
                <a href="http://www.cs.utexas.edu/~huangqx/">Qixing Huang</a>, 
              
                
                Zimo Li, 
              
                
                <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a>, 
              
                
                <a href="http://www.jianxiongxiao.com/">Jianxiong Xiao</a>, 
              
                
                <a href="https://cs.stanford.edu/~ericyi/">Li Yi</a>, 
              
                
                <a href="http://yf.io/">Fisher Yu</a><br>
              
              arXiv:1512.03012 [cs.GR], Dec 2015<br>
              
              
                 
                   
                   <a href="http://arxiv.org/pdf/1512.03012v1">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://shapenet.cs.stanford.edu/resources/shapenet.bib">bib</a> 
                   
                 
              
                 
                    | 
                   <a href="https://github.com/ShapeNet">code</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://shapenet.cs.stanford.edu/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_33" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/software/scenegraph-parser.shtml"><img src="files/twomen.png" alt="Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/scenegraph-parser.shtml">
                Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval
                </a>
              </h4>
              
                
                <a href="http://sebschu.com/">Sebastian Schuster</a>, 
              
                
                <a href="http://www.ranjaykrishna.com/">Ranjay Krishna</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://vision.stanford.edu/feifeili/">Li Fei-Fei</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Fourth Workshop on Vision and Language (VL15)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/~sebschu/pubs/schuster-krishna-chang-feifei-manning-vl15.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/~sebschu/pubs/schuster-krishna-chang-feifei-manning-vl15.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/software/scenegraph-parser.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_34" data-maintags="vision,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/semgeo/"><img src="files/semgeo.png" alt="Semantically-Enriched 3D Models for Common-sense Knowledge" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/semgeo/">
                Semantically-Enriched 3D Models for Common-sense Knowledge
                </a>
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              CVPR 2015 Vision meets Cognition Workshop<br>
              
              
                 
                   
                   <a href="http://graphics.stanford.edu/projects/semgeo/semgeo.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://graphics.stanford.edu/projects/semgeo/semgeo.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://graphics.stanford.edu/projects/semgeo/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_35" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/data/text2scene.shtml"><img src="files/lexground.png" alt="Text to 3D Scene Generation with Rich Lexical Grounding" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/data/text2scene.shtml">
                Text to 3D Scene Generation with Rich Lexical Grounding
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://wmonroeiv.github.io/">Will Monroe</a>, 
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://web.stanford.edu/~cgpotts/">Christopher Potts</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of ACL 2015<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/chang-acl2015-lexground.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/chang-acl2015-lexground.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/data/text2scene.shtml">webpage</a> 
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2014</h3>
                  
          <div class="row paper vertical-center" id="pub_36" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/scenegrok/"><img src="files/scenegrok.png" alt="SceneGrok: Inferring Action Maps in 3D Environments" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/scenegrok/">
                SceneGrok: Inferring Action Maps in 3D Environments
                </a>
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, 
              
                
                <a href="https://techmatt.github.io/">Matthew Fisher</a>, 
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a><br>
              
              Proceedings of SIGGRAPH Asia 2014<br>
              
              
                 
                   
                   <a href="http://graphics.stanford.edu/projects/scenegrok/scenegrok.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://graphics.stanford.edu/projects/scenegrok/scenegrok.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://graphics.stanford.edu/projects/scenegrok/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_37" data-maintags="graphics,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/sizes/"><img src="files/sizes.png" alt="On Being the Right Scale: Sizing Large Collections of 3D Models" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/sizes/">
                On Being the Right Scale: Sizing Large Collections of 3D Models
                </a>
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~gilbo/">Gilbert Bernstein</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              SIGGRAPH Asia 2014 Workshop on Indoor Scene Understanding: Where Graphics meets Vision<br>
              
              
                 
                   
                   <a href="http://graphics.stanford.edu/projects/sizes/sizes.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://graphics.stanford.edu/projects/sizes/sizes.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://graphics.stanford.edu/projects/sizes/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_38" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/projects/text2scene.shtml"><img src="files/spatialLearning.png" alt="Learning Spatial Knowledge for Text to 3D Scene Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/projects/text2scene.shtml">
                Learning Spatial Knowledge for Text to 3D Scene Generation
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/spatial-emnlp2014.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/spatial-emnlp2014.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/projects/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_39" data-maintags="vision,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="files/fpic2014.pdf"><img src="files/fpic2014.png" alt="Learning Affordance Maps by Observing Interactions" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Learning Affordance Maps by Observing Interactions
                
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://techmatt.github.io/">Matthew Fisher</a>, 
              
                
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie√üner</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              CVPR 2014 Workshop on Functionality, Physics, Intentionality and Causality<br>
              
              
                 
                   
                   <a href="files/fpic2014.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="files/fpic2014.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_40" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/projects/text2scene.shtml"><img src="files/interactiveLearning.png" alt="Interactive Learning of Spatial Knowledge for Text to 3D Scene Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/projects/text2scene.shtml">
                Interactive Learning of Spatial Knowledge for Text to 3D Scene Generation
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of the ACL 2014 Workshop on Interactive Language Learning, Visualization, and Interfaces<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/scenegen-aclviz2014.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/scenegen-aclviz2014.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/projects/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_41" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/projects/text2scene.shtml"><img src="files/semanticParsing.png" alt="Semantic Parsing for Text to 3D Scene Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/projects/text2scene.shtml">
                Semantic Parsing for Text to 3D Scene Generation
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of the ACL 2014 Workshop on Semantic Parsing<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/scenegen-sp2014.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/scenegen-sp2014.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/projects/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_42" data-maintags="hci,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/transphoner/"><img src="files/transphoner.png" alt="TransPhoner: Automated Mnemonic Keyword Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/transphoner/">
                TransPhoner: Automated Mnemonic Keyword Generation
                </a>
              </h4>
              
                
                <a href="https://msavva.github.io/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              Proceedings of CHI 2014<br>
              
              
                 
                   
                   <a href="http://graphics.stanford.edu/projects/transphoner/TransPhoner.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://graphics.stanford.edu/projects/transphoner/TransPhoner.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://graphics.stanford.edu/projects/transphoner/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_43" data-maintags="nlp,preprint">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/tokensregex.shtml">
                TokensRegex: Defining cascaded regular expressions over tokens
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Stanford University Technical Report<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/tokensregex-tr-2014.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/tokensregex-tr-2014.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/software/tokensregex.shtml">webpage</a> 
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2013</h3>
                  
          <div class="row paper vertical-center" id="pub_44" data-maintags="nlp,journal">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/software/dcoref.shtml"><img src="files/corefSieves.png" alt="Deterministic coreference resolution based on entity-centric, precision-ranked rules" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/dcoref.shtml">
                Deterministic coreference resolution based on entity-centric, precision-ranked rules
                </a>
              </h4>
              
                
                Heeyoung Lee, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.yvespeirsman.be/">Yves Peirsman</a>, 
              
                
                <a href="http://www.usna.edu/Users/cs/nchamber/">Nathanael Chambers</a>, 
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              In Computational Linguistics 39(4)<br>
              
              
                 
                   
                   <a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00152">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/software/dcoref.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_45" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford's 2013 KBP System
                
              </h4>
              
                
                <a href="http://cs.stanford.edu/~angeli/">Gabor Angeli</a>, 
              
                
                <a href="http://arun.chagantys.org/">Arun Tejasvi Chaganty</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://sites.google.com/site/kevinreschke/">Kevin Reschke</a>, 
              
                
                Julie Tibshirani, 
              
                
                Jean Y. Wu, 
              
                
                <a href="https://obastani.github.io/">Osbert Bastani</a>, 
              
                
                Keith Siilats, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Sixth Text Analysis Conference (TAC 2014)<br>
              
              
                 
                   
                   <a href="http://stanford.edu/~angeli/papers/2014-tac-kbp.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_46" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                SUTime: Evaluation in TempEval-3
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)<br>
              
              
                 
                   
                   <a href="http://aclweb.org/anthology/S/S13/S13-2013.pdf">pdf</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2012</h3>
                  
          <div class="row paper vertical-center" id="pub_47" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Joint Entity and Event Coreference Resolution across Documents
                
              </h4>
              
                
                Heeyoung Lee, 
              
                
                <a href="http://clic.ub.edu/users/marta-recasens">Marta Recasens</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              Proceedings of the Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/emnlp2012-coref.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/emnlp2012-coref.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_48" data-maintags="nlp,resources">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/software/sutime.shtml"><img src="files/sutime.png" alt="SUTime: A Library for Recognizing and Normalizing Time Expressions." class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/sutime.shtml">
                SUTime: A Library for Recognizing and Normalizing Time Expressions.
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC 2012)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/lrec2012-sutime.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/lrec2012-sutime.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/lrec2012-sutime-poster.pdf">poster</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu:8080/sutime">demo</a> 
                   
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/software/sutime.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_49" data-maintags="nlp,resources">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                A Cross-Lingual Dictionary for English Wikipedia Concepts
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC 2012)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/crosswikis.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/crosswikis.bib">bib</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/crosswikis-data.tar.bz2">data</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/crosswikis-slides.pdf">slides</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="https://plus.google.com/117790530324740296539/posts/VSjc4KYpug2">post</a> 
                   
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2011</h3>
                  
          <div class="row paper vertical-center" id="pub_50" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford's Distantly-Supervised Slot-Filling System
                
              </h4>
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.cs.stanford.edu/people/sonal/">Sonal Gupta</a>, 
              
                
                John Bauer, 
              
                
                <a href="http://nlp.stanford.edu/~mcclosky/">David McClosky</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Fourth Text Analysis Conference (TAC 2011)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/kbp2011-slotfilling.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2011-slotfilling.bib">bib</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp_trigger_words.txt">data</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_51" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Strong Baselines for Cross-Lingual Entity Linking
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              In Proceedings of the Fourth Text Analysis Conference (TAC 2011)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/kbp2011-crosslinking.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2011-crosslinking.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_52" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford-UBC Entity Linking at TAC-KBP, Again
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Fourth Text Analysis Conference (TAC 2011)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/kbp2011-entitylinking.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2011-entitylinking.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_53" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Unsupervised Dependency Parsing without Gold Part-of-Speech Tags
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                Hiyan Alshawi, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/goldtags.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/goldtags.bib">bib</a> 
                   
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/goldtags-data.tar.bz2">data</a> 
                   
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/goldtags-poster.pdf">poster</a> 
                   
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_54" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/dcoref.shtml">
                Stanford's Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task
                </a>
              </h4>
              
                
                Heeyoung Lee, 
              
                
                <a href="http://nlp.yvespeirsman.be/">Yves Peirsman</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.usna.edu/Users/cs/nchamber/">Nathanael Chambers</a>, 
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              In Proceedings of the CoNLL-2011 Shared Task<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/conllst2011-coref.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/conllst2011-coref.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
               | <a href="http://nlp.stanford.edu/software/dcoref.shtml">webpage</a> 
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2010</h3>
                  
          <div class="row paper vertical-center" id="pub_55" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                A Simple Distant Supervision Approach for the TAC-KBP Slot Filling Task
                
              </h4>
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://nlp.stanford.edu/~mcclosky/">David McClosky</a>, 
              
                
                Julie Tibshirani, 
              
                
                John Bauer, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Third Text Analysis Conference (TAC 2010)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/kbp2010-slotfilling.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2010-slotfilling.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2010-slotfilling-slides.pptx">slides</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_56" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford-UBC Entity Linking at TAC-KBP
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://www.ai.sri.com/people/yeh/">Eric Yeh</a>, 
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Third Text Analysis Conference (TAC 2010)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/kbp2010-entitylinking.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2010-entitylinking.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/kbp2010-entitylinking-poster.pdf">poster</a> 
                   
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2009</h3>
                  
          <div class="row paper vertical-center" id="pub_57" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford-UBC at TAC-KBP
                
              </h4>
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://www.ai.sri.com/people/yeh/">Eric Yeh</a><br>
              
              In Proceedings of the Second Text Analysis Conference (TAC 2009)<br>
              
              
                 
                   
                   <a href="http://nlp.stanford.edu/pubs/subctackbp.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/subctackbp.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
                    | 
                   <a href="http://nlp.stanford.edu/pubs/subctackbp-slides.pdf">slides</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
      
        <div class="year">
          <h3>2000</h3>
                  
          <div class="row paper vertical-center" id="pub_58" data-maintags="msic,journal">
            <div class="col-sm-3 paper-img">
            
              <a href="pubs/dragonbound.pdf"><img src="files/dragonCurve.png" alt="The Fractal Geometry of the Boundary of Dragon Curves" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                The Fractal Geometry of the Boundary of Dragon Curves
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                Tianrong Zhang<br>
              
              In Journal of Recreational Mathematics 30 (1), 9-22<br>
              
              
                 
                   
                   <a href="pubs/dragonbound.pdf">pdf</a> 
                   
                 
              
                 
                    | 
                   <a href="pubs/dragonbound.bib">bib</a> 
                   
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
                 
              
              
            </div>
          </div>
        

        </div>
          

      </div>
    </div>

  </div>
</div>
    </section>
    <footer>
      <p class="pull-right">
        Last updated at 2021-06-16T19:06:11.812Z
      </p>
    </footer>
  </div><!-- /container -->
</body>
</html>
